
â¸»
 AI-Driven Healthcare Intake Automation Pipeline

End-to-end data cleaning, validation, routing, and AI summarization using SQLite, Python, and local Llama 3 (Ollama).

â¸»

ğŸ“˜ Overview

This project implements a realistic healthcare intake operations pipeline.
It processes intake notes and insurance information through a full data workflow:
	1.	Extract data from SQLite
	2.	Clean inconsistent fields
	3.	Validate insurance information
	4.	Route each intake into operational queues
	5.	Enrich notes with AI summaries using a local LLM (Llama 3 via Ollama)
	6.	Persist enriched data back into the database
	7.	Analyze operational metrics and generate case-study samples

## â­ Project Highlights (What this demonstrates)

- Built an end-to-end healthcare intake pipeline: cleaning â†’ validation â†’ routing â†’ AI enrichment â†’ writeback â†’ analytics
- Integrated a local LLM (Llama 3 via Ollama) to generate summaries and structured extractions (risk + insurance issues)
- Implemented hybrid routing logic (rules + AI signals) with persisted v2 outputs in SQLite
- Added human-in-the-loop evaluation:
  - labeled ground truth set
  - confusion table scoring
  - severity-weighted scoring to reflect healthcare risk
- Delivered a Streamlit triage dashboard for filtering by queue, risk, and insurance issue type

The goal is to demonstrate real-world AI Ops, Product Ops, and Healthcare Data Engineering capability.

â¸»

ğŸ—ï¸ Architecture

SQLite â†’ Python ETL â†’ Cleaning â†’ Validation â†’ Routing â†’ AI Summaries â†’ Writeback â†’ Analytics

	â€¢	SQLite stores source tables (patients, visits, incidents, claims, intake)
	â€¢	Python ETL modules load, clean, validate, and route intake data
	â€¢	Ollama (Llama 3) generates concise AI summaries for intake notes
	â€¢	Analytics + case study scripts output operational insights and examples

â¸»

ğŸ“‚ Project Structure

ai-ops-roadmap/
â”‚
â”œâ”€â”€ SQL/
â”‚   â”œâ”€â”€ create_*.sql           # schema creation
â”‚   â”œâ”€â”€ insert_*.sql           # sample data loaders
â”‚   â””â”€â”€ *_queries.sql          # analytics queries
â”‚
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ data_loader.py         # load any SQL table into Pandas
â”‚   â”œâ”€â”€ clean_intake.py        # normalize intake fields
â”‚   â”œâ”€â”€ validate_intake.py     # detect missing/bad insurance, bad formats
â”‚   â”œâ”€â”€ intake_pipeline.py     # full clean + validate pipeline
â”‚   â”œâ”€â”€ router.py              # rule-based intake routing engine
â”‚   â”œâ”€â”€ writeback_intake.py    # write routed results to SQLite + CSV
â”‚   â”œâ”€â”€ ai_summarizer.py       # Llama 3 summarization via Ollama
â”‚   â”œâ”€â”€ writeback_intake_ai.py # write LLM summaries to DB
â”‚   â”œâ”€â”€ analytics_intake.py    # operational KPIs
â”‚   â””â”€â”€ case_study_intake_ai.py# narrative examples per routing queue
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ intake_routed_ai.csv   # exported AI-enriched data
â”‚
â””â”€â”€ healthcare_ops.db          # SQLite database


â¸»

ğŸ”„ Workflow Overview

1. Intake Cleaning
	â€¢	Standardizes insurance provider names
	â€¢	Strips policy numbers
	â€¢	Normalizes note text

2. Validation Layer

Flags:
	â€¢	missing insurance provider
	â€¢	missing policy number
	â€¢	invalid policy number (too short or malformed)
	â€¢	suspicious characters (?, -, etc.)

3. Rule-Based Routing Engine

Routes each intake into:

Queue	Reason
insurance_followup	Missing/invalid insurance info
prior_auth_team	Mentions â€œauthâ€, â€œauthorizationâ€
clinical_review	Contains clinical risk terms (falls, confusion, wound, behavior)
general_intake	Everything else

4. AI Summaries (Llama 3 via Ollama)

Each intake note is condensed into a 1â€“2 sentence summary highlighting:
	â€¢	clinical risk
	â€¢	insurance issues
	â€¢	operational follow-up needs

5. Writeback Layer

AI-enriched output is stored in:

intake_routed_ai

and exported to:

data/intake_routed_ai.csv

6. Analytics & Case Study Views

Python scripts analyze:
	â€¢	queue distribution
	â€¢	follow-up rates
	â€¢	payer-specific routing patterns
	â€¢	clinical workload distribution
	â€¢	AI-enhanced case samples

â¸»

ğŸ“Š Example Output (Case Study)

=== Queue: clinical_review (3 samples) ===

Intake ID: 14
Insurance Provider: Blue Cross
Needs Follow-up: No

Original Note:
  Behavioral changes observed, family concerned about mood.

AI Summary:
  Patient showing behavioral changes and mood concerns; may require evaluation by clinical team.

------------------------------------------------------------
â¸»

ğŸ§  Why This Project Matters

Healthcare operations deal with:
	â€¢	messy text
	â€¢	inconsistent insurance data
	â€¢	high-risk patient notes
	â€¢	prior authorization complexity
	â€¢	heavy manual review

This project demonstrates the ability to:
	â€¢	Design ETL pipelines
	â€¢	Implement validation & routing systems
	â€¢	Integrate local LLMs
	â€¢	Persist enriched operational data
	â€¢	Produce meaningful analytics

It aligns strongly with roles in:
	â€¢	AI Ops
	â€¢	Healthcare Product Operations
	â€¢	Clinical Operations Engineering
	â€¢	Data Engineering / ETL
	â€¢	AI Workflow Automation

â¸»

ğŸ›  Installation & Usage

1. Start Ollama

ollama serve
ollama pull llama3

2. Run the pipeline

python3 python/writeback_intake.py

3. Generate AI summaries

python3 python/writeback_intake_ai.py

4. Operational analytics

python3 python/analytics_intake.py

5. Case-study samples

python3 python/case_study_intake_ai.py

## Quickstart (Local)

### 1) Install dependencies
```bash
pip install -r requirements.txt


## ğŸ“¸ Demo Screenshots

### Worklist View
![Worklist](screenshots/dashboard_worklist.png)

### Case Viewer
![Case Viewer](screenshots/dashboard_case_view.png)

â¸»

## ğŸ”§ What Iâ€™d improve next (Production hardening)

- Add automated tests for routing rules + extraction parsing
- Add batch processing + concurrency controls for LLM calls
- Add monitoring metrics (drift, cache hit rate, latency)
- Add role-based access and audit logging for clinical workflows
- Deploy as a service (FastAPI) with a hosted dashboard


â¸»

ğŸ“„ License

MIT License.

â¸»
